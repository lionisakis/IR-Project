# @package _global_
defaults:
  - ../dataset@eval_dataset: msmarco_doc_pairs
  - override /dataset@train_dataset: msmarco_doc_triplets
  - override /model: reranker_global_score_qmlp_dmlm_long
exp_name: reranker_global_score_qmlp_dmlm_msmarco_doc_3_psg

resume_from_checkpoint: lsr42/qmlp_dmlm_msmarco_distil_kl_l1_0.0001

train_dataset:
  num_psg: 3
eval_dataset:
  num_psgs: 3
  run_path: "run_files_top200/run_max_score_1.trec"
training_arguments: 
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  max_steps: 150000
  gradient_accumulation_steps: 1
  # dataset@eval_dataset: msmarco_rerank
data_collator:
  _target_: lsr.datasets.multi_psgs_triplets.MutiPSGsTripletsBatching
  tokenizer: ${tokenizer}
  
eval_collator: 
  _target_: lsr.datasets.multi_psgs_pairs.MutiPSGsPairsBatching
  tokenizer: ${tokenizer}

trainer: 
  eval_collator: ${eval_collator}
  eval_dataset: ${eval_dataset}

wandb:
  setup:
    project: lsr-framework-phrase
